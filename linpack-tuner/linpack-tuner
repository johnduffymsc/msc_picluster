#!/usr/bin/bash

NODES=1
CORES_PER_NODE=4
GIGABYTES_PER_NODE=4
MEMORY_PERCENT=12.5
NB_START=32
NB_STOP=256
NB_INCREMENT=8


HPL_DAT = """\
HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
0            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
N?           Ns
1            # of NBs
NB?          NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
P?           Ps
Q?           Qs
16.0         threshold
3            # of panel fact
0 1 2        PFACTs (0=left, 1=Crout, 2=Right)
2            # of recursive stopping criterium
2 4          NBMINs (>= 1)
1            # of panels in recursion
2            NDIVs
3            # of recursive panel fact.
0 1 2        RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
0            BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
0            DEPTHs (>=0)
2            SWAP (0=bin-exch,1=long,2=mix)
64           swapping threshold
0            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (> 0)
"""


def calculate_n(nodes, gigabytes_per_node, memory_percentage, nb):
    """
    This function returns the parameter N.
    """
    return int(
        (
            (
                memory_percentage
                / 100
                * math.sqrt(nodes * gigabytes_per_node * 1024 ** 3 / 8)
            )
            // nb
        )
        * nb
    )


#def calculate_pq(nodes, cores_per_node):
#    """
#    This function returns a list of P and Q tuples.
#    """
#    pq = []
#    cores = nodes * cores_per_node
#    for i in range(1, int(math.sqrt(cores)) + 1):
#        if cores % i == 0 and i < cores // i:  # Ensure P < Q.
#            pq.append((i, cores // i))
#    return pq


#for memory_percent in MEMORY_PERCENT:
#
#    for nb in range(NB_START, NB_STOP + NB_INCREMENT, NB_INCREMENT):
#
#        n = calculate_n(NODES, GIGABYTES_PER_NODE, memory_percent, nb)
#
#        pq = calculate_pq(NODES, CORES_PER_NODE)
#
#        for i in range(len(pq)):
#
#            # Create a new HPL.dat file, populating it with n, nb, p and q.
#            try:
#                with open("HPL.dat", "w") as f:
#                    f.write(HPL_DAT.format(n, nb, pq[i][0], pq[i][1]))
#            except IOError as e:
#                print("I/O error: {0}".format(e))
#                exit()
#
#            # Run Linpack.
#            print(
#                "Running NODES={} N={} NB={} P={} Q={}... ".format(
#                    NODES, n, nb, pq[i][0], pq[i][1]
#                ),
#                end="",
#                flush=True,
#            )
#            try:
#                subprocess.run(["mpirun", "-hostfile", "nodes", "-np", "4", "xhpl"])
#            except:
#                os.remove("HPL.dat")
#                os.remove("HPL.out")
#                exit()
#            print("done", flush=True)
#
#            # Archive the current HPL.dat and HPL.out files.
#            try:
#                suffix = "{}_{}_{}_{}_{}".format(NODES, n, nb, pq[i][0], pq[i][1])
#                os.rename("HPL.dat", "HPL.dat.{}".format(suffix))
#                os.rename("HPL.out", "HPL.out.{}".format(suffix))
#            except IOError as e:
#                # The above archiving should work if we have got to this point.
#                print("I/O error: {0}".format(e))
